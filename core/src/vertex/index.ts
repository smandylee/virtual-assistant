/**
 * Vertex AI í†µí•© ëª¨ë“ˆ
 * - Gemini Pro/Flash (ëŒ€í™” ìƒì„±)
 * - Google Search Grounding (ì›¹ ê²€ìƒ‰)
 * - Embeddings (í…ìŠ¤íŠ¸ â†’ ë²¡í„°)
 * - Vector Search (ì¥ê¸° ê¸°ì–µ)
 */

import { VertexAI, GenerativeModel, GoogleSearchRetrieval, Tool } from "@google-cloud/vertexai";
import { PredictionServiceClient } from "@google-cloud/aiplatform";
import path from "path";
import fs from "fs/promises";

// GCP ì„¤ì •
const PROJECT_ID = "alphavertex-486307";
const LOCATION = "us-central1";
const KEY_FILE_PATH = path.join(process.cwd(), "gcp-key.json");

// í™˜ê²½ë³€ìˆ˜ ì„¤ì • (GCP ì¸ì¦ìš©)
process.env.GOOGLE_APPLICATION_CREDENTIALS = KEY_FILE_PATH;

// Vertex AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
let vertexAI: VertexAI | null = null;
let geminiModel: GenerativeModel | null = null;
let geminiModelWithSearch: GenerativeModel | null = null; // ğŸ” ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨ ëª¨ë¸
let embeddingClient: PredictionServiceClient | null = null;

// ì¥ê¸° ê¸°ì–µ ì €ì¥ì†Œ (ë¡œì»¬ ë²¡í„° ìŠ¤í† ì–´)
interface MemoryEntry {
  id: string;
  text: string;
  embedding: number[];
  timestamp: Date;
  type: "conversation" | "fact" | "preference" | "event";
  metadata?: Record<string, any>;
}

let memoryStore: MemoryEntry[] = [];
const MEMORY_FILE = path.join(process.cwd(), "data", "vector_memory.json");

/**
 * Vertex AI ì´ˆê¸°í™”
 */
export async function initVertexAI(): Promise<boolean> {
  try {
    // í‚¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
    await fs.access(KEY_FILE_PATH);
    
    // Vertex AI ì´ˆê¸°í™”
    vertexAI = new VertexAI({
      project: PROJECT_ID,
      location: LOCATION,
    });
    
    // Gemini ëª¨ë¸ ì´ˆê¸°í™” (ì¼ë°˜ ëŒ€í™”ìš©) - Gemini 3.0 Flash Preview
    geminiModel = vertexAI.getGenerativeModel({
      model: "gemini-3-flash-preview",
    });
    
    // ğŸ” Gemini ëª¨ë¸ ì´ˆê¸°í™” (Google Search Grounding í¬í•¨)
    geminiModelWithSearch = vertexAI.getGenerativeModel({
      model: "gemini-3-flash-preview",
      tools: [
        {
          googleSearchRetrieval: {
            disableAttribution: false,
          },
        } as Tool,
      ],
    });
    
    // Embedding í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    embeddingClient = new PredictionServiceClient({
      keyFilename: KEY_FILE_PATH,
    });
    
    // ì €ì¥ëœ ë©”ëª¨ë¦¬ ë¡œë“œ
    await loadMemory();
    
    console.log("âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ");
    console.log(`   - Project: ${PROJECT_ID}`);
    console.log(`   - Location: ${LOCATION}`);
    console.log(`   - ì €ì¥ëœ ë©”ëª¨ë¦¬: ${memoryStore.length}ê°œ`);
    
    return true;
  } catch (error: any) {
    console.error("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨:", error.message);
    return false;
  }
}

/**
 * Geminië¡œ ëŒ€í™” ìƒì„± (Vertex AI ë²„ì „)
 */
export async function chatWithVertexGemini(
  message: string,
  context?: string,
  systemPrompt?: string
): Promise<string> {
  if (!geminiModel) {
    await initVertexAI();
    if (!geminiModel) {
      throw new Error("Vertex AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }
  }
  
  try {
    // ê´€ë ¨ ê¸°ì–µ ê²€ìƒ‰
    const relevantMemories = await searchMemory(message, 5);
    
    // ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    let fullContext = systemPrompt || "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ë¹„ì„œì…ë‹ˆë‹¤.";
    
    if (relevantMemories.length > 0) {
      fullContext += "\n\nğŸ“š ê´€ë ¨ ê¸°ì–µ:\n";
      relevantMemories.forEach((mem, i) => {
        fullContext += `${i + 1}. [${mem.type}] ${mem.text}\n`;
      });
    }
    
    if (context) {
      fullContext += `\n\nì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: ${context}`;
    }
    
    // Gemini í˜¸ì¶œ
    const result = await geminiModel.generateContent({
      contents: [
        {
          role: "user",
          parts: [{ text: `${fullContext}\n\nì‚¬ìš©ì: ${message}` }]
        }
      ],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2048,
      }
    });
    
    const response = result.response;
    const reply = response.candidates?.[0]?.content?.parts?.[0]?.text || "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
    
    // ëŒ€í™” ê¸°ì–µ ì €ì¥
    await addMemory(message, "conversation", { role: "user" });
    await addMemory(reply, "conversation", { role: "assistant" });
    
    return reply;
  } catch (error: any) {
    console.error("Vertex Gemini ì˜¤ë¥˜:", error);
    throw error;
  }
}

/**
 * í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (Embedding)
 */
export async function getEmbedding(text: string): Promise<number[]> {
  if (!embeddingClient) {
    await initVertexAI();
    if (!embeddingClient) {
      throw new Error("Embedding í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }
  }
  
  try {
    const endpoint = `projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/text-embedding-004`;
    
    const [response] = await embeddingClient.predict({
      endpoint,
      instances: [{ content: text }] as any,
    });
    
    const embedding = (response.predictions?.[0] as any)?.embeddings?.values;
    
    if (!embedding) {
      throw new Error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨");
    }
    
    return embedding;
  } catch (error: any) {
    console.error("Embedding ì˜¤ë¥˜:", error);
    // í´ë°±: ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”© (í…ŒìŠ¤íŠ¸ìš©)
    return simpleHash(text);
  }
}

/**
 * ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”© (Vertex AI ì‹¤íŒ¨ ì‹œ í´ë°±)
 */
function simpleHash(text: string): number[] {
  const embedding = new Array(768).fill(0);
  for (let i = 0; i < text.length; i++) {
    const charCode = text.charCodeAt(i);
    embedding[i % 768] += charCode / 1000;
  }
  // ì •ê·œí™”
  const magnitude = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
  return embedding.map(val => val / (magnitude || 1));
}

/**
 * ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
 */
function cosineSimilarity(a: number[], b: number[]): number {
  if (a.length !== b.length) return 0;
  
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  
  const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
  return magnitude === 0 ? 0 : dotProduct / magnitude;
}

/**
 * ê¸°ì–µ ì¶”ê°€
 */
export async function addMemory(
  text: string,
  type: MemoryEntry["type"],
  metadata?: Record<string, any>
): Promise<string> {
  try {
    const embedding = await getEmbedding(text);
    const id = `mem_${Date.now()}_${Math.random().toString(36).substring(7)}`;
    
    const entry: MemoryEntry = {
      id,
      text,
      embedding,
      timestamp: new Date(),
      type,
      metadata
    };
    
    memoryStore.push(entry);
    
    // ì£¼ê¸°ì ìœ¼ë¡œ ì €ì¥ (100ê°œë§ˆë‹¤)
    if (memoryStore.length % 100 === 0) {
      await saveMemory();
    }
    
    console.log(`ğŸ’¾ ê¸°ì–µ ì €ì¥: [${type}] ${text.substring(0, 50)}...`);
    return id;
  } catch (error: any) {
    console.error("ê¸°ì–µ ì¶”ê°€ ì˜¤ë¥˜:", error);
    throw error;
  }
}

/**
 * ìœ ì‚¬í•œ ê¸°ì–µ ê²€ìƒ‰
 */
export async function searchMemory(
  query: string,
  topK: number = 5,
  typeFilter?: MemoryEntry["type"]
): Promise<MemoryEntry[]> {
  try {
    const queryEmbedding = await getEmbedding(query);
    
    // í•„í„°ë§
    let candidates = memoryStore;
    if (typeFilter) {
      candidates = memoryStore.filter(m => m.type === typeFilter);
    }
    
    // ìœ ì‚¬ë„ ê³„ì‚° ë° ì •ë ¬
    const scored = candidates.map(mem => ({
      ...mem,
      score: cosineSimilarity(queryEmbedding, mem.embedding)
    }));
    
    scored.sort((a, b) => b.score - a.score);
    
    // ìƒìœ„ Kê°œ ë°˜í™˜ (ìœ ì‚¬ë„ 0.5 ì´ìƒë§Œ)
    return scored
      .filter(m => m.score > 0.5)
      .slice(0, topK)
      .map(({ score, ...rest }) => rest);
  } catch (error: any) {
    console.error("ê¸°ì–µ ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return [];
  }
}

/**
 * íŠ¹ì • íƒ€ì…ì˜ ê¸°ì–µ ì¡°íšŒ
 */
export function getMemoriesByType(type: MemoryEntry["type"]): MemoryEntry[] {
  return memoryStore.filter(m => m.type === type);
}

/**
 * ê¸°ì–µ ì €ì¥ (íŒŒì¼ë¡œ)
 */
export async function saveMemory(): Promise<void> {
  try {
    // data ë””ë ‰í† ë¦¬ ìƒì„±
    await fs.mkdir(path.dirname(MEMORY_FILE), { recursive: true });
    
    // JSONìœ¼ë¡œ ì €ì¥
    await fs.writeFile(MEMORY_FILE, JSON.stringify(memoryStore, null, 2));
    console.log(`ğŸ’¾ ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ: ${memoryStore.length}ê°œ`);
  } catch (error: any) {
    console.error("ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜:", error);
  }
}

/**
 * ê¸°ì–µ ë¡œë“œ (íŒŒì¼ì—ì„œ)
 */
export async function loadMemory(): Promise<void> {
  try {
    const data = await fs.readFile(MEMORY_FILE, "utf-8");
    memoryStore = JSON.parse(data);
    console.log(`ğŸ“‚ ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ: ${memoryStore.length}ê°œ`);
  } catch (error: any) {
    // íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ì‹œì‘
    memoryStore = [];
    console.log("ğŸ“‚ ìƒˆ ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ ì‹œì‘");
  }
}

/**
 * ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ ë° ì €ì¥ (ëŒ€í™”ì—ì„œ ìë™ ì¶”ì¶œ)
 */
export async function extractAndSaveImportantInfo(
  conversation: string
): Promise<string[]> {
  if (!geminiModel) {
    await initVertexAI();
  }
  
  try {
    const result = await geminiModel!.generateContent({
      contents: [{
        role: "user",
        parts: [{
          text: `ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì¥ê¸°ì ìœ¼ë¡œ ê¸°ì–µí•´ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ê° ì •ë³´ëŠ” ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
- fact: ì‚¬ì‹¤ ì •ë³´ (ì´ë¦„, ì§ì—…, ê´€ì‹¬ì‚¬ ë“±)
- preference: ì„ í˜¸ë„ (ì¢‹ì•„í•˜ëŠ” ê²ƒ, ì‹«ì–´í•˜ëŠ” ê²ƒ)
- event: ì´ë²¤íŠ¸/ì¼ì • (ì•½ì†, ê¸°ë…ì¼ ë“±)

JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
[{"type": "fact", "text": "ì‚¬ìš©ìì˜ ì´ë¦„ì€ ..."}, ...]

ëŒ€í™”:
${conversation}

ì¤‘ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.`
        }]
      }],
      generationConfig: {
        temperature: 0.3,
      }
    });
    
    const responseText = result.response.candidates?.[0]?.content?.parts?.[0]?.text || "[]";
    
    // JSON ì¶”ì¶œ
    const jsonMatch = responseText.match(/\[[\s\S]*\]/);
    if (!jsonMatch) return [];
    
    const extracted = JSON.parse(jsonMatch[0]) as Array<{ type: string; text: string }>;
    const savedIds: string[] = [];
    
    for (const item of extracted) {
      const type = item.type as MemoryEntry["type"];
      if (["fact", "preference", "event"].includes(type)) {
        const id = await addMemory(item.text, type);
        savedIds.push(id);
      }
    }
    
    // ë³€ê²½ì‚¬í•­ ì €ì¥
    if (savedIds.length > 0) {
      await saveMemory();
    }
    
    return savedIds;
  } catch (error: any) {
    console.error("ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜:", error);
    return [];
  }
}

/**
 * ê¸°ì–µ í†µê³„
 */
export function getMemoryStats(): {
  total: number;
  byType: Record<string, number>;
  oldest?: Date;
  newest?: Date;
} {
  const byType: Record<string, number> = {
    conversation: 0,
    fact: 0,
    preference: 0,
    event: 0
  };
  
  for (const mem of memoryStore) {
    byType[mem.type] = (byType[mem.type] || 0) + 1;
  }
  
  const timestamps = memoryStore.map(m => new Date(m.timestamp).getTime());
  
  return {
    total: memoryStore.length,
    byType,
    oldest: timestamps.length > 0 ? new Date(Math.min(...timestamps)) : undefined,
    newest: timestamps.length > 0 ? new Date(Math.max(...timestamps)) : undefined
  };
}

/**
 * ì˜¤ë˜ëœ ê¸°ì–µ ì •ë¦¬
 */
export async function cleanupOldMemories(maxAge: number = 30 * 24 * 60 * 60 * 1000): Promise<number> {
  const cutoff = Date.now() - maxAge;
  const before = memoryStore.length;
  
  // conversation íƒ€ì…ë§Œ ì •ë¦¬ (fact, preference, eventëŠ” ìœ ì§€)
  memoryStore = memoryStore.filter(m => 
    m.type !== "conversation" || new Date(m.timestamp).getTime() > cutoff
  );
  
  const removed = before - memoryStore.length;
  
  if (removed > 0) {
    await saveMemory();
    console.log(`ğŸ§¹ ì˜¤ë˜ëœ ê¸°ì–µ ì •ë¦¬: ${removed}ê°œ ì‚­ì œ`);
  }
  
  return removed;
}

/**
 * ğŸ” Vertex AI ì›¹ ê²€ìƒ‰ (Google Search Grounding)
 * Google Custom Search API ëŒ€ì‹  Vertex AIì˜ Grounding ê¸°ëŠ¥ ì‚¬ìš©
 */
export async function searchWithVertex(
  query: string,
  options?: {
    maxResults?: number;
    language?: string;
  }
): Promise<{
  success: boolean;
  query: string;
  answer: string;
  sources?: Array<{ title: string; url: string; snippet: string }>;
  error?: string;
}> {
  if (!geminiModelWithSearch) {
    await initVertexAI();
    if (!geminiModelWithSearch) {
      return {
        success: false,
        query,
        answer: "",
        error: "Vertex AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      };
    }
  }
  
  try {
    console.log(`ğŸ” Vertex AI ê²€ìƒ‰: ${query}`);
    
    const result = await geminiModelWithSearch.generateContent({
      contents: [{
        role: "user",
        parts: [{
          text: `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: ${query}

ë‹µë³€ í˜•ì‹:
1. í•µì‹¬ ë‹µë³€ì„ ë¨¼ì € ì œê³µ
2. ê´€ë ¨ ì„¸ë¶€ ì •ë³´ ì¶”ê°€
3. ì¶œì²˜ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.`
        }]
      }],
      generationConfig: {
        temperature: 0.3,
        maxOutputTokens: 2048,
      }
    });
    
    const response = result.response;
    const answer = response.candidates?.[0]?.content?.parts?.[0]?.text || "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
    
    // Grounding metadataì—ì„œ ì¶œì²˜ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
    const groundingMetadata = (response.candidates?.[0] as any)?.groundingMetadata;
    const sources: Array<{ title: string; url: string; snippet: string }> = [];
    
    if (groundingMetadata?.webSearchQueries) {
      console.log('ê²€ìƒ‰ ì¿¼ë¦¬:', groundingMetadata.webSearchQueries);
    }
    
    if (groundingMetadata?.groundingChunks) {
      for (const chunk of groundingMetadata.groundingChunks) {
        if (chunk.web) {
          sources.push({
            title: chunk.web.title || "ì¶œì²˜",
            url: chunk.web.uri || "",
            snippet: ""
          });
        }
      }
    }
    
    console.log(`âœ… Vertex AI ê²€ìƒ‰ ì™„ë£Œ, ì¶œì²˜ ${sources.length}ê°œ`);
    
    return {
      success: true,
      query,
      answer,
      sources: sources.length > 0 ? sources : undefined
    };
    
  } catch (error: any) {
    console.error("Vertex AI ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return {
      success: false,
      query,
      answer: "",
      error: error.message || "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    };
  }
}

/**
 * ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ (Vertex AI)
 */
export async function searchNewsWithVertex(
  query: string,
  maxResults: number = 5
): Promise<{
  success: boolean;
  query: string;
  answer: string;
  error?: string;
}> {
  return searchWithVertex(`${query} ìµœì‹  ë‰´ìŠ¤`, { maxResults });
}

// ê¸°ë³¸ export
export default {
  initVertexAI,
  chatWithVertexGemini,
  getEmbedding,
  addMemory,
  searchMemory,
  getMemoriesByType,
  saveMemory,
  loadMemory,
  extractAndSaveImportantInfo,
  getMemoryStats,
  cleanupOldMemories,
  searchWithVertex,
  searchNewsWithVertex
};
