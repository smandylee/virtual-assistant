/**
 * Vertex AI í†µí•© ëª¨ë“ˆ
 * - Gemini 3.0 Flash (ëŒ€í™” ìƒì„±)
 * - Google Search Grounding (ì›¹ ê²€ìƒ‰)
 * - Embeddings (í…ìŠ¤íŠ¸ â†’ ë²¡í„°)
 * - Firestore í†µí•© (ì¥ê¸° ê¸°ì–µ + ì¤‘ì•™ DB)
 */

import { VertexAI, GenerativeModel, GoogleSearchRetrieval, Tool } from "@google-cloud/vertexai";
import { PredictionServiceClient } from "@google-cloud/aiplatform";
import path from "path";
import fs from "fs/promises";

// Firestore í†µí•© (ë²¡í„° ê¸°ì–µ + ì¤‘ì•™ DB)
import {
  initFirestore,
  isConnected as isFirestoreConnected,
  addMemory as firestoreAddMemory,
  searchMemory as firestoreSearchMemory,
  getMemoriesByType as firestoreGetMemoriesByType,
  getMemoryStats as firestoreGetMemoryStats,
  cleanupOldMemories as firestoreCleanupOldMemories,
  type MemoryType,
  type MemoryEntry,
  type MemorySearchResult,
} from "../memory/firestore.js";

import { unifiedSearch, formatForContext } from "../memory/router.js";

// GCP ì„¤ì •
const PROJECT_ID = "alphavertex-486307";
const LOCATION = "us-central1";
const KEY_FILE_PATH = path.join(process.cwd(), "gcp-key.json");

// í™˜ê²½ë³€ìˆ˜ ì„¤ì • (GCP ì¸ì¦ìš©)
process.env.GOOGLE_APPLICATION_CREDENTIALS = KEY_FILE_PATH;

// Vertex AI í´ë¼ì´ì–¸íŠ¸
let vertexAI: VertexAI | null = null;
let geminiModel: GenerativeModel | null = null;
let geminiModelWithSearch: GenerativeModel | null = null;
let embeddingClient: PredictionServiceClient | null = null;

// Firestore ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ (í´ë°±: JSON ë©”ëª¨ë¦¬)
let useFirestore = false;

// JSON í´ë°±ìš© ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
interface LegacyMemoryEntry {
  id: string;
  text: string;
  embedding: number[];
  timestamp: Date;
  type: "conversation" | "fact" | "preference" | "event";
  metadata?: Record<string, any>;
}

let legacyMemoryStore: LegacyMemoryEntry[] = [];
const MEMORY_FILE = path.join(process.cwd(), "data", "vector_memory.json");

/**
 * Vertex AI + Firestore í†µí•© ì´ˆê¸°í™”
 */
export async function initVertexAI(): Promise<boolean> {
  try {
    // í‚¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
    await fs.access(KEY_FILE_PATH);

    // Vertex AI ì´ˆê¸°í™”
    vertexAI = new VertexAI({
      project: PROJECT_ID,
      location: LOCATION,
    });

    // Gemini ëª¨ë¸ ì´ˆê¸°í™” (ì¼ë°˜ ëŒ€í™”ìš©)
    geminiModel = vertexAI.getGenerativeModel({
      model: "gemini-3-flash-preview",
    });

    // Gemini ëª¨ë¸ ì´ˆê¸°í™” (Google Search Grounding í¬í•¨)
    geminiModelWithSearch = vertexAI.getGenerativeModel({
      model: "gemini-3-flash-preview",
      tools: [
        {
          googleSearchRetrieval: {
            disableAttribution: false,
          },
        } as Tool,
      ],
    });

    // Embedding í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    embeddingClient = new PredictionServiceClient({
      keyFilename: KEY_FILE_PATH,
    });

    console.log("âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ");
    console.log(`   - Project: ${PROJECT_ID}`);
    console.log(`   - Location: ${LOCATION}`);

    // Firestore ì´ˆê¸°í™” ì‹œë„
    useFirestore = await initFirestore();
    if (useFirestore) {
      console.log("âœ… Firestore í†µí•© ë©”ëª¨ë¦¬ í™œì„±í™”");
    } else {
      console.log("âš ï¸ Firestore ë¯¸ì—°ê²° â†’ JSON í´ë°± ë©”ëª¨ë¦¬ ì‚¬ìš©");
      await loadLegacyMemory();
      console.log(`   - JSON ë©”ëª¨ë¦¬: ${legacyMemoryStore.length}ê°œ`);
    }

    return true;
  } catch (error: any) {
    console.error("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨:", error.message);
    return false;
  }
}

/**
 * Geminië¡œ ëŒ€í™” ìƒì„± (ë©”ëª¨ë¦¬ ë¼ìš°í„° í†µí•©)
 */
export async function chatWithVertexGemini(
  message: string,
  context?: string,
  systemPrompt?: string
): Promise<string> {
  if (!geminiModel) {
    await initVertexAI();
    if (!geminiModel) {
      throw new Error("Vertex AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }
  }

  try {
    // ë©”ëª¨ë¦¬ ë¼ìš°í„°ë¡œ í†µí•© ê²€ìƒ‰
    const searchResult = await unifiedSearch(message, { topK: 5 });
    const contextFromMemory = formatForContext(searchResult);

    // ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    let fullContext = systemPrompt || "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ë¹„ì„œì…ë‹ˆë‹¤.";

    if (contextFromMemory) {
      fullContext += `\n\n${contextFromMemory}`;
    }

    if (context) {
      fullContext += `\n\nì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: ${context}`;
    }

    // Gemini í˜¸ì¶œ
    const result = await geminiModel.generateContent({
      contents: [
        {
          role: "user",
          parts: [{ text: `${fullContext}\n\nì‚¬ìš©ì: ${message}` }],
        },
      ],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2048,
      },
    });

    const response = result.response;
    const reply =
      response.candidates?.[0]?.content?.parts?.[0]?.text ||
      "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";

    // ëŒ€í™” ê¸°ì–µ ì €ì¥
    await addMemory(message, "conversation", { role: "user" });
    await addMemory(reply, "conversation", { role: "assistant" });

    return reply;
  } catch (error: any) {
    console.error("Vertex Gemini ì˜¤ë¥˜:", error);
    throw error;
  }
}

/**
 * í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (Embedding)
 */
export async function getEmbedding(text: string): Promise<number[]> {
  if (!embeddingClient) {
    await initVertexAI();
    if (!embeddingClient) {
      throw new Error("Embedding í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }
  }

  try {
    const endpoint = `projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/text-embedding-004`;

    const [response] = await embeddingClient.predict({
      endpoint,
      instances: [{ content: text }] as any,
    });

    const embedding = (response.predictions?.[0] as any)?.embeddings?.values;

    if (!embedding) {
      throw new Error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨");
    }

    return embedding;
  } catch (error: any) {
    console.error("Embedding ì˜¤ë¥˜:", error);
    return simpleHash(text);
  }
}

/**
 * ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”© (Vertex AI ì‹¤íŒ¨ ì‹œ í´ë°±)
 */
function simpleHash(text: string): number[] {
  const embedding = new Array(768).fill(0);
  for (let i = 0; i < text.length; i++) {
    const charCode = text.charCodeAt(i);
    embedding[i % 768] += charCode / 1000;
  }
  const magnitude = Math.sqrt(
    embedding.reduce((sum: number, val: number) => sum + val * val, 0)
  );
  return embedding.map((val: number) => val / (magnitude || 1));
}

/**
 * ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (JSON í´ë°±ìš©)
 */
function cosineSimilarity(a: number[], b: number[]): number {
  if (a.length !== b.length) return 0;

  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }

  const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
  return magnitude === 0 ? 0 : dotProduct / magnitude;
}

// ==================== ë©”ëª¨ë¦¬ í•¨ìˆ˜ (Firestore ìš°ì„ , JSON í´ë°±) ====================

/**
 * ê¸°ì–µ ì¶”ê°€
 */
export async function addMemory(
  text: string,
  type: MemoryType,
  metadata?: Record<string, any>
): Promise<string> {
  if (useFirestore) {
    const embedding = await getEmbedding(text);
    return firestoreAddMemory(text, type, embedding, metadata);
  }

  // JSON í´ë°±
  try {
    const embedding = await getEmbedding(text);
    const id = `mem_${Date.now()}_${Math.random().toString(36).substring(7)}`;

    const entry: LegacyMemoryEntry = {
      id,
      text,
      embedding,
      timestamp: new Date(),
      type,
      metadata,
    };

    legacyMemoryStore.push(entry);

    if (legacyMemoryStore.length % 100 === 0) {
      await saveLegacyMemory();
    }

    console.log(`ğŸ’¾ ê¸°ì–µ ì €ì¥ (JSON): [${type}] ${text.substring(0, 50)}...`);
    return id;
  } catch (error: any) {
    console.error("ê¸°ì–µ ì¶”ê°€ ì˜¤ë¥˜:", error);
    throw error;
  }
}

/**
 * ìœ ì‚¬í•œ ê¸°ì–µ ê²€ìƒ‰
 */
export async function searchMemory(
  query: string,
  topK: number = 5,
  typeFilter?: MemoryType
): Promise<MemoryEntry[]> {
  if (useFirestore) {
    const queryEmbedding = await getEmbedding(query);
    return firestoreSearchMemory(queryEmbedding, topK, typeFilter);
  }

  // JSON í´ë°±
  try {
    const queryEmbedding = await getEmbedding(query);

    let candidates = legacyMemoryStore;
    if (typeFilter) {
      candidates = legacyMemoryStore.filter((m) => m.type === typeFilter);
    }

    const scored = candidates.map((mem) => ({
      id: mem.id,
      text: mem.text,
      type: mem.type as MemoryType,
      timestamp: new Date(mem.timestamp).toISOString(),
      metadata: mem.metadata,
      score: cosineSimilarity(queryEmbedding, mem.embedding),
    }));

    scored.sort((a, b) => b.score - a.score);

    return scored
      .filter((m) => m.score > 0.5)
      .slice(0, topK)
      .map(({ score, ...rest }) => rest);
  } catch (error: any) {
    console.error("ê¸°ì–µ ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return [];
  }
}

/**
 * íŠ¹ì • íƒ€ì…ì˜ ê¸°ì–µ ì¡°íšŒ
 */
export async function getMemoriesByType(
  type: MemoryType
): Promise<MemoryEntry[]> {
  if (useFirestore) {
    return firestoreGetMemoriesByType(type);
  }
  return legacyMemoryStore
    .filter((m) => m.type === type)
    .map((m) => ({
      id: m.id,
      text: m.text,
      type: m.type as MemoryType,
      timestamp: new Date(m.timestamp).toISOString(),
      metadata: m.metadata,
    }));
}

/**
 * ê¸°ì–µ ì €ì¥
 */
export async function saveMemory(): Promise<void> {
  if (useFirestore) {
    // FirestoreëŠ” ìë™ ì˜ì† â†’ ë³„ë„ ì €ì¥ ë¶ˆí•„ìš”
    return;
  }
  await saveLegacyMemory();
}

async function saveLegacyMemory(): Promise<void> {
  try {
    await fs.mkdir(path.dirname(MEMORY_FILE), { recursive: true });
    await fs.writeFile(
      MEMORY_FILE,
      JSON.stringify(legacyMemoryStore, null, 2)
    );
    console.log(`ğŸ’¾ JSON ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ: ${legacyMemoryStore.length}ê°œ`);
  } catch (error: any) {
    console.error("ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜:", error);
  }
}

async function loadLegacyMemory(): Promise<void> {
  try {
    const data = await fs.readFile(MEMORY_FILE, "utf-8");
    legacyMemoryStore = JSON.parse(data);
    console.log(`ğŸ“‚ JSON ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ: ${legacyMemoryStore.length}ê°œ`);
  } catch (error: any) {
    legacyMemoryStore = [];
    console.log("ğŸ“‚ ìƒˆ ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ ì‹œì‘");
  }
}

/**
 * JSON â†’ Firestore ë§ˆì´ê·¸ë ˆì´ì…˜
 */
export async function migrateMemoryToFirestore(): Promise<number> {
  if (!useFirestore) {
    throw new Error("Firestoreê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.");
  }

  try {
    const data = await fs.readFile(MEMORY_FILE, "utf-8");
    const jsonMemories: LegacyMemoryEntry[] = JSON.parse(data);
    if (jsonMemories.length === 0) return 0;

    let migrated = 0;
    for (const mem of jsonMemories) {
      await firestoreAddMemory(
        mem.text,
        mem.type as MemoryType,
        mem.embedding,
        mem.metadata
      );
      migrated++;

      if (migrated % 50 === 0) {
        console.log(`ğŸ“¦ ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰: ${migrated}/${jsonMemories.length}`);
      }
    }

    console.log(`âœ… JSON â†’ Firestore ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${migrated}ê°œ`);
    return migrated;
  } catch {
    console.log("ë§ˆì´ê·¸ë ˆì´ì…˜í•  JSON ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.");
    return 0;
  }
}

/**
 * ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ ë° ì €ì¥
 */
export async function extractAndSaveImportantInfo(
  conversation: string
): Promise<string[]> {
  if (!geminiModel) {
    await initVertexAI();
  }

  try {
    const result = await geminiModel!.generateContent({
      contents: [
        {
          role: "user",
          parts: [
            {
              text: `ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì¥ê¸°ì ìœ¼ë¡œ ê¸°ì–µí•´ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ê° ì •ë³´ëŠ” ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
- fact: ì‚¬ì‹¤ ì •ë³´ (ì´ë¦„, ì§ì—…, ê´€ì‹¬ì‚¬ ë“±)
- preference: ì„ í˜¸ë„ (ì¢‹ì•„í•˜ëŠ” ê²ƒ, ì‹«ì–´í•˜ëŠ” ê²ƒ)
- event: ì´ë²¤íŠ¸/ì¼ì • (ì•½ì†, ê¸°ë…ì¼ ë“±)

JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
[{"type": "fact", "text": "ì‚¬ìš©ìì˜ ì´ë¦„ì€ ..."}, ...]

ëŒ€í™”:
${conversation}

ì¤‘ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.`,
            },
          ],
        },
      ],
      generationConfig: {
        temperature: 0.3,
      },
    });

    const responseText =
      result.response.candidates?.[0]?.content?.parts?.[0]?.text || "[]";

    const jsonMatch = responseText.match(/\[[\s\S]*\]/);
    if (!jsonMatch) return [];

    const extracted = JSON.parse(jsonMatch[0]) as Array<{
      type: string;
      text: string;
    }>;
    const savedIds: string[] = [];

    for (const item of extracted) {
      const type = item.type as MemoryType;
      if (["fact", "preference", "event"].includes(type)) {
        const id = await addMemory(item.text, type);
        savedIds.push(id);
      }
    }

    return savedIds;
  } catch (error: any) {
    console.error("ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜:", error);
    return [];
  }
}

/**
 * ê¸°ì–µ í†µê³„
 */
export async function getMemoryStats(): Promise<{
  total: number;
  byType: Record<string, number>;
}> {
  if (useFirestore) {
    return firestoreGetMemoryStats();
  }

  const byType: Record<string, number> = {
    conversation: 0,
    fact: 0,
    preference: 0,
    event: 0,
  };

  for (const mem of legacyMemoryStore) {
    byType[mem.type] = (byType[mem.type] || 0) + 1;
  }

  return { total: legacyMemoryStore.length, byType };
}

/**
 * ì˜¤ë˜ëœ ê¸°ì–µ ì •ë¦¬
 */
export async function cleanupOldMemories(
  maxAge: number = 30 * 24 * 60 * 60 * 1000
): Promise<number> {
  if (useFirestore) {
    return firestoreCleanupOldMemories(maxAge);
  }

  const cutoff = Date.now() - maxAge;
  const before = legacyMemoryStore.length;

  legacyMemoryStore = legacyMemoryStore.filter(
    (m) =>
      m.type !== "conversation" ||
      new Date(m.timestamp).getTime() > cutoff
  );

  const removed = before - legacyMemoryStore.length;

  if (removed > 0) {
    await saveLegacyMemory();
    console.log(`ğŸ§¹ ì˜¤ë˜ëœ ê¸°ì–µ ì •ë¦¬: ${removed}ê°œ ì‚­ì œ`);
  }

  return removed;
}

/**
 * Vertex AI ì›¹ ê²€ìƒ‰ (Google Search Grounding)
 */
export async function searchWithVertex(
  query: string,
  options?: {
    maxResults?: number;
    language?: string;
  }
): Promise<{
  success: boolean;
  query: string;
  answer: string;
  sources?: Array<{ title: string; url: string; snippet: string }>;
  error?: string;
}> {
  if (!geminiModelWithSearch) {
    await initVertexAI();
    if (!geminiModelWithSearch) {
      return {
        success: false,
        query,
        answer: "",
        error: "Vertex AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      };
    }
  }

  try {
    console.log(`ğŸ” Vertex AI ê²€ìƒ‰: ${query}`);

    const result = await geminiModelWithSearch.generateContent({
      contents: [
        {
          role: "user",
          parts: [
            {
              text: `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: ${query}

ë‹µë³€ í˜•ì‹:
1. í•µì‹¬ ë‹µë³€ì„ ë¨¼ì € ì œê³µ
2. ê´€ë ¨ ì„¸ë¶€ ì •ë³´ ì¶”ê°€
3. ì¶œì²˜ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.`,
            },
          ],
        },
      ],
      generationConfig: {
        temperature: 0.3,
        maxOutputTokens: 2048,
      },
    });

    const response = result.response;
    const answer =
      response.candidates?.[0]?.content?.parts?.[0]?.text ||
      "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";

    const groundingMetadata = (response.candidates?.[0] as any)
      ?.groundingMetadata;
    const sources: Array<{ title: string; url: string; snippet: string }> = [];

    if (groundingMetadata?.webSearchQueries) {
      console.log("ê²€ìƒ‰ ì¿¼ë¦¬:", groundingMetadata.webSearchQueries);
    }

    if (groundingMetadata?.groundingChunks) {
      for (const chunk of groundingMetadata.groundingChunks) {
        if (chunk.web) {
          sources.push({
            title: chunk.web.title || "ì¶œì²˜",
            url: chunk.web.uri || "",
            snippet: "",
          });
        }
      }
    }

    console.log(`âœ… Vertex AI ê²€ìƒ‰ ì™„ë£Œ, ì¶œì²˜ ${sources.length}ê°œ`);

    return {
      success: true,
      query,
      answer,
      sources: sources.length > 0 ? sources : undefined,
    };
  } catch (error: any) {
    console.error("Vertex AI ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return {
      success: false,
      query,
      answer: "",
      error: error.message || "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
    };
  }
}

/**
 * ë‰´ìŠ¤ ê²€ìƒ‰ (Vertex AI)
 */
export async function searchNewsWithVertex(
  query: string,
  maxResults: number = 5
): Promise<{
  success: boolean;
  query: string;
  answer: string;
  error?: string;
}> {
  return searchWithVertex(`${query} ìµœì‹  ë‰´ìŠ¤`, { maxResults });
}

// Re-export íƒ€ì…
export type { MemoryType, MemoryEntry, MemorySearchResult };

// ê¸°ë³¸ export
export default {
  initVertexAI,
  chatWithVertexGemini,
  getEmbedding,
  addMemory,
  searchMemory,
  getMemoriesByType,
  saveMemory,
  extractAndSaveImportantInfo,
  getMemoryStats,
  cleanupOldMemories,
  searchWithVertex,
  searchNewsWithVertex,
  migrateMemoryToFirestore,
};
